{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook: Limpieza y modelos XGBoost\n",
        "\n",
        "Este notebook realiza:\n",
        "- Limpieza robusta del dataset `Fleet_Work_Orders_20251111.csv`.\n",
        "- Tres pipelines de modelado con XGBoost:\n",
        "  1. Regresión para **`Total Cost`**.\n",
        "  2. Clasificación para **`On Time Indicator`** (Y/N).\n",
        "  3. Regresión para **`Days to next revision`** (heurística: tiempo hasta la siguiente orden del mismo vehículo).\n",
        "\n",
        "Cada celda incluye explicación y pasos para que sea reproducible. Guarda el notebook y ejecútalo en el mismo folder donde está el CSV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar librerías necesarias (ejecutar solo si hace falta)\n",
        "!pip install -q xgboost scikit-learn pandas matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Ruta del CSV (debe estar en el mismo directorio que este notebook)\n",
        "CSV_PATH = 'Fleet_Work_Orders_20251111.csv'\n",
        "assert Path(CSV_PATH).exists(), f\"No encontré {CSV_PATH} en el directorio actual.\"\n",
        "\n",
        "# Cargar y mostrar primeras filas\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Información rápida\n",
        "df.info()\n",
        "df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limpieza y normalización\n",
        "Convertiremos fechas, forcemos conversión numérica en columnas clave, limpiamos textos y creamos la variable \"days to next revision\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "date_cols = [\n",
        "    'In Service Date',\n",
        "    'Work Order Begin Date',\n",
        "    'Work Order Finish Date'\n",
        "]\n",
        "for c in date_cols:\n",
        "    df[c] = pd.to_datetime(df[c], errors='coerce')\n",
        "\n",
        "# Limpiar textos\n",
        "text_cols = ['Vehicle Make', 'Vehicle Model', 'WO Reason']\n",
        "for c in text_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = df[c].astype(str).str.strip().str.upper().replace({'NAN':'UNKNOWN'})\n",
        "\n",
        "# Normalizar indicadores\n",
        "if 'On Time Indicator' in df.columns:\n",
        "    df['On Time Indicator'] = df['On Time Indicator'].astype(str).str.upper().str.strip()\n",
        "    df['On Time Indicator'] = df['On Time Indicator'].replace({'YES':'Y','NO':'N','1':'Y','0':'N'})\n",
        "    df['On Time Indicator'] = df['On Time Indicator'].replace({'NAN':'UNKNOWN'})\n",
        "\n",
        "if 'Open Indicator' in df.columns:\n",
        "    df['Open Indicator'] = df['Open Indicator'].astype(str).str.upper().str.strip()\n",
        "    df['Open Indicator'] = df['Open Indicator'].replace({'YES':'Y','NO':'N','1':'Y','0':'N'})\n",
        "    df['Open Indicator'] = df['Open Indicator'].replace({'NAN':'UNKNOWN'})\n",
        "\n",
        "# Forzar y limpiar numéricos importantes\n",
        "numeric_fix_cols = [\n",
        "    'Total Cost',\n",
        "    'Expected Hours',\n",
        "    'Actual Hours',\n",
        "    'Days to Complete',\n",
        "    'WO Vehicle Odometer',\n",
        "    'Vehicle Year'\n",
        "]\n",
        "for col in numeric_fix_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str).str.replace(',', '', regex=False).str.replace('$','',regex=False).str.strip()\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Rellenar numéricos con 0 por defecto (puedes cambiar la estrategia)\n",
        "for col in numeric_fix_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "# Eliminar duplicados\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Mostrar resumen\n",
        "df[numeric_fix_cols].dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Crear target: days to next revision\n",
        "Calcularemos para cada vehículo el número de días hasta la siguiente orden: para cada grupo por `Vehicle Number`, ordenamos por `Work Order Begin Date` y calculamos la diferencia entre la siguiente `Work Order Begin Date` y la fila actual `Work Order Finish Date`. Si no existe siguiente orden, pondremos `NaN` y luego rellenaremos con 0 (o la mediana si prefieres).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'Vehicle Number' in df.columns and 'Work Order Begin Date' in df.columns and 'Work Order Finish Date' in df.columns:\n",
        "    df = df.sort_values(['Vehicle Number','Work Order Begin Date'])\n",
        "    df['next_begin'] = df.groupby('Vehicle Number')['Work Order Begin Date'].shift(-1)\n",
        "    df['days_to_next_revision'] = (df['next_begin'] - df['Work Order Finish Date']).dt.days\n",
        "    # si negative o NaN -> rellenar con 0\n",
        "    df['days_to_next_revision'] = df['days_to_next_revision'].apply(lambda x: x if pd.notna(x) and x>=0 else np.nan)\n",
        "    df['days_to_next_revision'] = df['days_to_next_revision'].fillna(0)\n",
        "else:\n",
        "    df['days_to_next_revision'] = 0\n",
        "\n",
        "df['days_to_next_revision'].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparar features y targets para los tres problemas:\n",
        "1. Regression -> `Total Cost`\n",
        "2. Classification -> `On Time Indicator` (Y/N). Convertiremos a 1/0.\n",
        "3. Regression -> `days_to_next_revision`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir features base\n",
        "feature_cols = [\n",
        "    'Total Cost',\n",
        "    'Expected Hours',\n",
        "    'Days to Complete',\n",
        "    'WO Vehicle Odometer',\n",
        "    'Vehicle Year',\n",
        "    'Vehicle Make',\n",
        "    'Vehicle Model',\n",
        "    'WO Reason',\n",
        "    'On Time Indicator',\n",
        "    'Open Indicator'\n",
        "]\n",
        "# Filtrar las columnas que realmente existen\n",
        "feature_cols = [c for c in feature_cols if c in df.columns]\n",
        "feature_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Targets\n",
        "y_cost = df['Total Cost']\n",
        "y_time = df['Actual Hours']\n",
        "y_next = df['days_to_next_revision']\n",
        "\n",
        "# Features copy\n",
        "X = df[feature_cols].copy()\n",
        "X.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convertir categóricas a tipo `category` y asegurar que 'UNKNOWN' exista\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "for c in cat_cols:\n",
        "    X[c] = X[c].astype(str).str.upper().str.strip().replace({'NAN':'UNKNOWN'})\n",
        "    X[c] = X[c].astype('category')\n",
        "    if 'UNKNOWN' not in X[c].cat.categories:\n",
        "        X[c] = X[c].cat.add_categories(['UNKNOWN'])\n",
        "\n",
        "X.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separar numéricas y categóricas (ahora categories están como 'category')\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64', 'Int64']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['category']).columns.tolist()\n",
        "num_cols, cat_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rellenar NaNs: numéricos -> 0, categóricas -> 'UNKNOWN'\n",
        "X.loc[:, num_cols] = X[num_cols].fillna(0)\n",
        "for col in cat_cols:\n",
        "    if 'UNKNOWN' not in X[col].cat.categories:\n",
        "        X[col] = X[col].cat.add_categories(['UNKNOWN'])\n",
        "X.loc[:, cat_cols] = X[cat_cols].fillna('UNKNOWN')\n",
        "\n",
        "# Confirmar no hay NaNs\n",
        "print('NaNs in X:', X.isna().sum().sum())\n",
        "print('NaNs in y_time:', y_time.isna().sum())\n",
        "print('NaNs in y_cost:', y_cost.isna().sum())\n",
        "print('NaNs in y_next:', y_next.isna().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelado: XGBoost\n",
        "Entrenaremos 3 modelos (2 regresores y 1 clasificador)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "def train_and_eval_reg(X, y, label='reg'):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, enable_categorical=True)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    print(f\"{label} MAE: {mae:.4f} | RMSE: {rmse:.4f}\")\n",
        "    return model, X_test, y_test, preds\n",
        "\n",
        "def train_and_eval_clf(X, y, label='clf'):\n",
        "    # convertir target a 0/1 si viene como 'Y'/'N' o 'UNKNOWN'\n",
        "    y2 = y.astype(str).str.upper().map({'Y':1, 'N':0})\n",
        "    y2 = y2.fillna(0)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
        "    model = XGBClassifier(n_estimators=200, max_depth=6, enable_categorical=True)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds, zero_division=0)\n",
        "    print(f\"{label} ACC: {acc:.4f} | F1: {f1:.4f}\")\n",
        "    print(classification_report(y_test, preds, zero_division=0))\n",
        "    return model, X_test, y_test, preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Modelo para **Total Cost** (regresión)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cost, Xc_test, yc_test, preds_cost = train_and_eval_reg(X, y_cost, label='TotalCost')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Modelo para **Actual Hours** (regresión)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_time, Xt_test, yt_test, preds_time = train_and_eval_reg(X, y_time, label='ActualHours')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Modelo para **Days to next revision** (regresión)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_next, Xn_test, yn_test, preds_next = train_and_eval_reg(X, y_next, label='DaysNext')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Clasificador para **On Time Indicator** (si prefieres clasificación)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'On Time Indicator' in X.columns:\n",
        "    model_on_time, Xot_test, yot_test, preds_ot = train_and_eval_clf(X, df['On Time Indicator'], label='OnTime')\n",
        "else:\n",
        "    print('No se encontró On Time Indicator en X')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guardar modelos\n",
        "Guardamos los modelos entrenados para usarlos luego desde FastAPI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cost.save_model('model_cost.json')\n",
        "model_time.save_model('model_time.json')\n",
        "model_next.save_model('model_next.json')\n",
        "if 'model_on_time' in globals():\n",
        "    model_on_time.save_model('model_on_time.json')\n",
        "print('Modelos guardados en el directorio actual')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejemplo de uso desde FastAPI\n",
        "Agrega estos snippets en tu `main.py` para exponer endpoints `/predict_cost`, `/predict_time`, `/predict_next` y `/predict_on_time`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat > fastapi_predict_snippets.txt <<'PY'\n",
        "# --- snippets para main.py ---\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Cargar modelos (en el startup de FastAPI)\n",
        "model_cost = xgb.XGBRegressor()\n",
        "model_cost.load_model('model_cost.json')\n",
        "\n",
        "model_time = xgb.XGBRegressor()\n",
        "model_time.load_model('model_time.json')\n",
        "\n",
        "model_next = xgb.XGBRegressor()\n",
        "model_next.load_model('model_next.json')\n",
        "\n",
        "model_on_time = None\n",
        "try:\n",
        "    model_on_time = xgb.XGBClassifier()\n",
        "    model_on_time.load_model('model_on_time.json')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Ejemplo de Pydantic para /predict_cost\n",
        "class CostInput(BaseModel):\n",
        "    Expected_Hours: float\n",
        "    Actual_Hours: float\n",
        "    Days_to_Completion: float\n",
        "    WO_Vehicle_Odometer: float\n",
        "    Vehicle_Year: int\n",
        "    Vehicle_Make: str\n",
        "    Vehicle_Model: str\n",
        "    WO_Reason: str\n",
        "    On_Time_Indicator: str\n",
        "    Open_Indicator: str\n",
        "\n",
        "# End of snippets\n",
        "PY\n",
        "echo 'Snippets guardados en fastapi_predict_snippets.txt'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fin del notebook\n",
        "Guarda y ejecuta las celdas en orden. Si quieres, puedo ajustar hiperparámetros, crear pipelines con búsqueda (GridSearch / Optuna) o integrar estas predicciones directamente como endpoints en `main.py`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
